\chapter{Conclusion and future work}
%\lhead{Introduction}
%\rhead{Radu-George Rusu}
Analyzing the result presented in the previous chapter we can see a pattern both on the real data sets and on the random ones. It is preferable to use either Hill Climbing or particle swarm optimization for this specific problem, because they yield better results both in terms of final output and also in terms of performances (time, CPU, memory). Also, from this results, we can say that it's more advantageous to use one those heuristics, rather than a deterministic algorithm. Although they may not yield the best result at every run, from a resource (time, memory) perspective, these heuristic are more convenient than a deterministic algorithm. In our concrete cases, on the real data sets, the exhaustive search algorithms took between 10 to 15 minutes to compute the final solution, while the heuristic ones were finished after 1 minute, with results similar to the exhaustive one.

Having this in mind, as a future point for this work, those algorithms can be ran on bigger datasets with more observations. The data sets used in this work are somehow of didactic size, and although the results are pretty good, we need a bigger scale to draw final results for real world data. Another point that can be used for future works is the usage of the optimization function. In this paper we used an estimator as the objective function instead of using a function that matches the data. A short example will be to use the sum squared errors function for a data set with a lot observations. We can split the initial data in training data (that will be used for running of the algorithm) and test data (that will be used for computing the objective function). In this way we will get solutions that are closer to the data that we used as input for the algorithm.

On the synthetic data, the results showed that this algorithms can fail in certain conditions. First of all, they were evaluated against a true solution, know before generating the input data, which is not necessarily the best solution in regards to AIC value. This can lead, in a future work, to usage of a different objective function (as described in the previous paragraph). To avoid the noise that we noticed with the 50 variables random data set, we can use other methods for variable selection (that can handle better that amount of noise), and chained it with the method presented here.

The last point of this work is the fact that the genetic algorithm behave quite poorly compared to the other 3 algorithms. This is mainly due to the representation of the solution and how the search space look like. For this algorithm 3 operators have been used, mutation, crossover and fortune wheel selection roulette. Although the first and the third one helps in optimizing this type of spaces, the crossover one actually adds more random solutions into the population, which explain in fact the slow convergence speed of this algorithm. As a future work the genetic algorithm can be run with other operators that are more suited for this type of solution spaces.

As final conclusions for this work, we can say that the Hill Climbing variations and Particle Swarm Optimization (as presented here) are a good choice when trying to solve this types of problems. The parameters can be tweaked to improve the performances of the algorithms, but this paper present a good starting point for new discoveries.